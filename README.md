# ğŸ–ï¸ HathSayBaat

### Indian Sign Language to Text & Speech Translator

HathSayBaat is an **offline, real-time Indian Sign Language (ISL) to Text and Speech Translator** created to make everyday communication easier for deaf and hard-of-hearing individuals. The idea behind this project is simple: **enable people to communicate naturally using hand gestures**, without depending on the internet, expensive hardware, or complex setup.

The system uses a normal webcam to capture hand gestures and converts them into readable text and clear speech using computer vision and deep learning techniques.

---

## ğŸŒŸ What HathSayBaat Can Do

* ğŸ¥ Recognizes ISL hand gestures in real time using a webcam
* ğŸ§  Uses a trained deep learning model for accurate gesture prediction
* ğŸ“ Converts gestures into readable text instantly
* ğŸ”Š Speaks the recognized text using text-to-speech
* ğŸŒ Supports multilingual output (English & Hindi)
* ğŸ“ Includes a video call feature with live ISL translation
* ğŸ” Secure login and user authentication
* ğŸ’» Works completely offline, ensuring user privacy

---

## ğŸ› ï¸ Technologies Used

**Frontend**

* HTML
* CSS
* JavaScript

**Backend**

* Python
* Flask
* Flask-Login
* Flask-SQLAlchemy

**Computer Vision & AI**

* OpenCV
* MediaPipe
* CVZone
* TensorFlow
* Keras

**Database**

* SQLite

---

## ğŸ§© How the System Works (Simple Explanation)

1. The webcam captures live video of hand gestures
2. OpenCV processes the video frames
3. MediaPipe detects and tracks hand landmarks
4. The gesture image is preprocessed for consistency
5. A trained deep learning model predicts the gesture
6. The recognized gesture is converted into text
7. Text is optionally translated into another language
8. Text-to-speech generates audio output

All of this happens **locally on the userâ€™s device**, without sending data anywhere.

---

## ğŸ“‚ Project Structure

```
HathSayBaat/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ keras_model.h5
â”œâ”€â”€ labels.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ uploads/
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ login.html
â”‚   â”œâ”€â”€ register.html
â”‚   â”œâ”€â”€ model.html
â”‚   â”œâ”€â”€ video_call.html
â”‚   â””â”€â”€ languages.html
â”‚
â”œâ”€â”€ instance/
â””â”€â”€ HandSignDetection/
```

---

## âš™ï¸ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Dik-sha08/HathSayBaat-Indian-Sign-Language-to-Text-Speech-Translator.git
cd HathSayBaat-Indian-Sign-Language-to-Text-Speech-Translator
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Application

```bash
python app.py
```

Then open your browser and visit:

```
http://127.0.0.1:5000
```

---

## ğŸ§  About the ML Model

* CNN-based gesture recognition model
* Trained using TensorFlow and Keras
* Input: Hand gesture images
* Output: ISL gesture labels

> If the model file size exceeds GitHub limits, it can be hosted externally and loaded locally.

---

## ğŸ” Privacy & Security

* No internet required
* No cloud storage
* No external APIs
* Webcam data processed locally
* User data is not stored unnecessarily

This makes HathSayBaat suitable for **education, healthcare, and personal use**.

---

## ğŸ”® Future Improvements

* Support for more ISL gestures and vocabulary
* Better sentence-level grammar handling
* Mobile and desktop application versions
* Emotion-aware gesture recognition
* Support for more Indian languages

---

## ğŸ‘©â€ğŸ’» Developed By

**Diksha Joshi**
MCA Student
Birla Institute of Applied Sciences


---

## ğŸ“œ License

This project is developed for **academic and learning purposes**.

---

âœ¨ *HathSayBaat is a small step towards making communication more inclusive, accessible, and human-friendly using AI.*

---

